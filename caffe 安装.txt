caffe 



操作系统: Ubuntu 16.04
是否使用PYTHON API: 是, 目标是安装后CAFFE能作为PYTHON MODULE来使用
硬件: 低端笔记本, 只使用CPU模式
 
这是我安装的过程, 并非安装教程. 相同情况下可以参考, 能省下一些看文档的时间.
参考: CAFFE官网安装指南页面http://caffe.berkeleyvision.org/installation.html#compilation
 
 
第一部分: 安装dependencies
sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
sudo apt-get install --no-install-recommends libboost-all-dev
sudo apt-get install libatlas-base-dev
sudo apt-get install libhdf5-serial-dev
     apt-get install libgoogle-glog-dev libgflags-dev liblmdb-dev
 
PYTHON需要2.7版本,这是操作系统本身已经安装好的. 输入python2.7 --version 会显示具体的版本号说明安装了.
但是还需要sudo apt-get install python-dev
 
sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev
(以上所有sudo apt-get在什么文件夹下输入都无所谓.)
 
然后把CAFFE的源代码下载下来: git clone https://github.com/BVLC/caffe.git
(当然没有安装GIT的得先安装一下)
下载完成之后,进入CAFFE文件夹, 进入里面的PYTHON文件夹,然后输入
for req in $(cat requirements.txt); do pip install $req; done
(PIP如果没有安装得先安装一下:sudo apt install python-pip)
 
第二部分: 安装CAFFE
到CAFFE文件夹, 使用模板写个Makefile.config. 具体就是先复制一下模板, 再改一些内容(我喜欢用EMACS).
cp Makefile.config.example Makefile.config
-因为CPU MODE, 所以在CPU_ONLY := 1前面的#要去掉.
-两个路径要改成这样:(添加后面的两个hdf5的路径, 否则编译时报hdf5错误)
# Whatever else you find you need goes here.
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial
 
准备好了.
make pycaffe
make all
make test
make runtest
--结果显示ALL TESTS PASSED就安装好了, 只需要再加上一个PYTHONPATH; 
另外, 这个make默认是用CPU单核运算,如果想要快一点, 比如我想使用四核, 在make后面加上-j4标签.
如果上面4行某一行报错之后想要重试,建议先make clean再重新开始.
 
 
第三部分: 设置 Python Caffe
去到CAFFE文件夹里面的python文件夹, 把当前路径记录下来(pwd). 然后输入以下命令(把记下的路径放在相应地方)
export PYTHONPATH=/usr/src/caffe/python/caffe:$PYTHONPATH
 
这时候应该可以了,试验一下:
$ python2.7
Python 2.7.12 (default, Jul  1 2016, 15:12:24) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import caffe
>>> 
说明安装全部完成!
 
第四部分: 错误
基本上所有错误都是因为dependencies缺乏或者路径不对,所以根据具体的错误信息对症下药.例如:
-编译时显示hdf5错误, 按照上面所说, 增加路径之后就解决了. 
-import caffe时显示scikit-image错误, 那就安装一下scikit-image就好了.
pip install scikit-image
 
很多人都在安装CAFFE时遇到各种错误, 请给多一点点耐心, 多谷歌一下, 一定能完成的。
Ubuntu 16.04下Matlab2014a+Anaconda2+OpenCV3.1+Caffe安装 http://www.linuxidc.com/Linux/2016-07/132860.htm

Ubuntu 16.04系统下CUDA7.5配置Caffe教程 http://www.linuxidc.com/Linux/2016-07/132859.htm

Caffe在Ubuntu 14.04 64bit 下的安装 http://www.linuxidc.com/Linux/2015-07/120449.htm

深度学习框架Caffe在Ubuntu下编译安装  http://www.linuxidc.com/Linux/2016-07/133225.htm

Caffe + Ubuntu 14.04 64bit + CUDA 6.5 配置说明  http://www.linuxidc.com/Linux/2015-04/116444.htm

Ubuntu 16.04上安装Caffe http://www.linuxidc.com/Linux/2016-08/134585.htm

Caffe配置简明教程 ( Ubuntu 14.04 / CUDA 7.5 / cuDNN 5.1 / OpenCV 3.1 )  http://www.linuxidc.com/Linux/2016-09/135016.htm

更多Ubuntu相关信息见Ubuntu 专题页面 http://www.linuxidc.com/topicnews.aspx?tid=2

本文永久更新链接地址：http://www.linuxidc.com/Linux/2016-09/135034.htm



















###################################   可能有的问题 1

ubuntu配置caffe遇到的问题
原创 2016年04月02日 14:51:15 标签：caffe环境配置 /ubuntu 12965
以下是本人在配置caffe遇到的问题，比较简单，但是由于网上现成的资料比较少，所以还是花了不少时间才解决它们。
在此把这些问题展示出来，希望能让和我一样的新手少走一些弯路。
环境 ubuntu15.10,cuda7.5,cudnn-7.0-linux-x64-v4-rc


1、make all步骤出现错误
./include/caffe/util/hdf5.hpp:6:18: fatal error: hdf5.h: No such file or directory

解决方法
在Makefile.config文件的第85行，添加 /usr/include/hdf5/serial/ 到 INCLUDE_DIRS，也就是把下面第一行代码改为第二行代码。
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/

在Makefile文件的第173行，把 hdf5_hl 和hdf5修改为hdf5_serial_hl 和 hdf5_serial，也就是把下面第一行代码改为第二行代码。
LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5
LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial

英文文档链接
https://gist.github.com/wangruohui/679b05fcd1466bb0937f

2、make pycaffe出现错误

python/caffe/_caffe.cpp:10:31: fatal error: numpy/arrayobject.h: no such file or directory
Makefile:498: recipe for target 'python/caffe/_caffe.so' failed make: *** [python/caffe/_caffe.so] Error 1

原因
python-numpy没有安装到位

解决方法
输入命令
sudo apt-get install python-numpy
确认Makefile.config文件中有以下代码，注意路径或版本号与自己的相符。
PYTHON_INCLUDE := /usr/include/python2.7 \
/usr/lib/python2.7/dist-packages/numpy/core/include

3.cudnn的安装
copy文件至CUDA安装目录:解压后,在你的目录下生成一个“cuda”文件夹,对于cuDNN6.5的版本解压后生成“cudnn­6.5­linux­x64­v2”文件。使用如下命令copy,注意第二个有个 -a 参数,否则,拷贝过去的文件失去了链接。
1 # copy the library files into CUDA's include and lib folders
2 sudo cp cuda/include/cudnn.h /usr/local/cuda/include
3 sudo cp -a cuda/lib64/libcudnn* /usr/local/cuda/lib64
cuDNN安装完成。
在这一步骤，按照网上的一些教程配置cudnn时，需要更新软链接，但是由于版本不同等原因，可能不能正确地输入更新软链接命令，通过-a参数，可以省去更新软链接命令。



Ubuntu下编译caffe
纯粹是个人编译的记录。不用CUDA（笔记本是amd卡，万恶的nvidia）；不手动编译依赖包（apt-get是用来干啥的？用来直接装二进制包，以及自动解决依赖项的）
caffe官方给出的ubuntu下的教程在http://caffe.berkeleyvision.org/install_apt.html

make: protoc: 命令未找到
解决办法：

sudo apt-get install protobuf-c-compiler protobuf-compiler
fatal error: gflags/gflags.h:没有那个文件或目录
解决办法：

sudo apt-get install libgflags-dev
顺便吐槽一下ubuntu的apt-get命令的补全，它是残破的。我想下载gflags，于是输入：

sudo apt-get install gflags #此处直接按tab，希望它补全，tab一次不出来就再按一次
结果呢，只显示了一个结果：

sudo apt-get install libgflags2v5
问题是，实际上有3个结果：libflags2v5,libgflags-dev,libgflags-doc

ubuntu的命令行，另一个残破的地方在于，各种包总是喜欢私自添加lib前缀，比如，好好的opencv，非得要libopencv才行（全名并不是libopencv和oepncv，通常都是用-dev或-devel各种的包）

fatal error: glog/logging.h: 没有那个文件或目录
尝试apt-get install glog，妈蛋，没有。要这样：

sudo apt-get install libgoogle-glog-dev
fatal error: hdf5.h: 没有那个文件或目录
妈蛋！老子执行过apt-get install hdf5-tools了，怎么还说没有hdf5？而且我当时tab了好几下，只有两个结果，另一个是hdf5-helpers不装也罢。
其实，这又是ubuntu的命令行比较残破的原因。为什么不能完整点搜索？

当然这次，需要的不仅仅是一个-dev包，因为试了后还是报同样错误，那就尝试：

sudo apt-get install libhdf5-\*  #我用的shell是zsh，如果你没有用zsh，那就是默认的bash，那就把“\”去掉。这，是zsh比较残破的地方
然后再make all，还是报同样错误。怒了，这次是caffe自身的问题。要在Makefile.config中把hdf5的一个目录添加进来：

# 找到这行：
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include

# 替换为：
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/
fatal error: lmdb.h: 没有那个文件或目录
擦，刚刚明明apt-get安装了lmdb-utils，怎么又来？而且，安装lmdb时tab了好几次只有这么一个有用的结果。
这次，又是ubuntu命令的残破引发的。

解决办法：

sudo apt-get install liblmdb-dev
make: *** [.build_release/lib/libcaffe.so.1.0.0-rc3] Error 1
这次的问题有点大了。问题完整描述：

AR -o .build_release/lib/libcaffe.a
LD -o .build_release/lib/libcaffe.so.1.0.0-rc3
/usr/bin/ld: cannot find -lboost_python3
collect2: error: ld returned 1 exit status
Makefile:563: recipe for target '.build_release/lib/libcaffe.so.1.0.0-rc3' failed
make: *** [.build_release/lib/libcaffe.so.1.0.0-rc3] Error 1
我也想不出办法，于是google之。发现caffe在github的repo上有人提出同样的问题：https://github.com/BVLC/caffe/issues/4045
然后，真是不友好或没有用的回答，维护caffe的都是什么鬼？！说什么，别在issue里提“使用，安装，编译出错”的问题，请使用caffe-users list。我就草，issue不是用来解决问题的么？user list是google group谷歌用户组，一个更不好用的东西，连markdown都没有，太落后了。anyway，这些都不管用。

管用的方法：再次修改Makefile.config（艹，caffe官方的Makefile.config你敢再残破一点么？市面上一共就3种最常用的跑caffe的平台，第一个就是ubuntu还搞这么用户不友好，第二个是fedora只能说还凑合因为fedora自身命令比ubuntu完善，第三个mac用户暂时不考虑，真正跑caffe的都是烧GPU的，mac用户管他干啥）

anyway，要这样改:

# 原来
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial

LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib

# 现在改成（64位系统）：
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial

LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial

# 或者，你是32位系统：
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial

LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/i386-linux-gnu /usr/lib/i386-linux-gnu/hdf5/serial
这样就好了么？天真。还得执行非常肮脏的sed脚本！

find . -type f -exec sed -i -e 's^"hdf5.h"^"hdf5/serial/hdf5.h"^g' -e 's^"hdf5_hl.h"^"hdf5/serial/hdf5_hl.h"^g' '{}' \;
这个可能是ubuntu自身的问题，也可能是caffe的问题。

blas的问题
作为小白用户，方便起见，用不着去搞MKL，一则申请麻烦，二则太大。同时也要尽量避免手动编译。手动编译源码可能带来更多的依赖项问题。所以尽可能全都用apt-get安装。

sudo apt-get install libopenblas-dev
reference
https://github.com/BVLC/caffe/wiki/Ubuntu-16.04-or-15.10-Installation-Guide
https://github.com/SHUCV/caffe_demo/wiki/install-caffe-on-ubuntu14.04

==== update 2016年11月5日 17:39:33 ====
换ubuntu16.04了，编译caffe时会提示：memcpy未定义
解决方法：Makefile中，找到：

NVCCFLAGS += -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)

换成

NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)














#####################################################   Caffe 步骤  ########################################################################################################## 
1. words.txt：分类序号与分类对应关系（注意：要从0开始标注）

0 cat
1 dog
2 fish
 

2. train.txt：标明训练图片路径及其对应分类，路径和分类序号直接用空格分隔，最好随机打乱一下图片

复制代码
/opt/caffe/examples/my_simple_image/data/cat_train/n02123045_4416.JPEG 0
/opt/caffe/examples/my_simple_image/data/cat_train/n02123045_3568.JPEG 0
/opt/caffe/examples/my_simple_image/data/fish_train/n02512053_4451.JPEG 2
/opt/caffe/examples/my_simple_image/data/cat_train/n02123045_3179.JPEG 0
/opt/caffe/examples/my_simple_image/data/cat_train/n02123045_6956.JPEG 0
/opt/caffe/examples/my_simple_image/data/cat_train/n02123045_10143.JPEG 0
......
 

3. val.txt：标明测试图片路径及其对应分类

/opt/caffe/examples/my_simple_image/data/dog_val/n02084071_12307.JPEG 1
/opt/caffe/examples/my_simple_image/data/dog_val/n02084071_10619.JPEG 1
/opt/caffe/examples/my_simple_image/data/cat_val/n02123045_13360.JPEG 0
/opt/caffe/examples/my_simple_image/data/cat_val/n02123045_13060.JPEG 0
/opt/caffe/examples/my_simple_image/data/cat_val/n02123045_11859.JPEG 0
......    



2、生成lmdb文件

lmdb是caffe使用的一种输入数据格式，相当于我们把图片及其分类重新整合一下，变成一个数据库输给caffe训练。

这里我们使用caffenet的create_imagenet.sh文件修改，主要是重新指定一下路径：

复制代码
EXAMPLE=examples/my_simple_image/
DATA=examples/my_simple_image/data/
TOOLS=build/tools

TRAIN_DATA_ROOT=/
VAL_DATA_ROOT=/

# 这里我们打开resize，需要把所有图片尺寸统一
RESIZE=true
if $RESIZE; then
  RESIZE_HEIGHT=256
  RESIZE_WIDTH=256
else
  RESIZE_HEIGHT=0
  RESIZE_WIDTH=0
fi

.......

echo "Creating train lmdb..."

GLOG_logtostderr=1 $TOOLS/convert_imageset \
    --resize_height=$RESIZE_HEIGHT \
    --resize_width=$RESIZE_WIDTH \
    --shuffle \
    $TRAIN_DATA_ROOT \
    $DATA/train.txt \
    $EXAMPLE/ilsvrc12_train_lmdb　　#生成的lmdb路径

echo "Creating val lmdb..."

GLOG_logtostderr=1 $TOOLS/convert_imageset \
    --resize_height=$RESIZE_HEIGHT \
    --resize_width=$RESIZE_WIDTH \
    --shuffle \
    $VAL_DATA_ROOT \
    $DATA/val.txt \
    $EXAMPLE/ilsvrc12_val_lmdb    #生成的lmdb路径
echo "Done."
复制代码
 

3、生成mean_file

下面我们用lmdb生成mean_file，用于训练（具体做啥用的我还没研究。。。）

这里也是用imagenet例子的脚本：

复制代码
EXAMPLE=examples/my_simple_image
DATA=examples/my_simple_image
TOOLS=build/tools

$TOOLS/compute_image_mean $EXAMPLE/ilsvrc12_train_lmdb $DATA/imagenet_mean.binaryproto

echo "Done."
复制代码
 

 

4、修改solver、train_val配置文件

这里我们可以选用cifar的网络，也可以用imagenet的网络，不过后者的网络结构更复杂一些，为了学习，我们就用cifar的网络来改。

把cifar的两个配置文件拷过来：

cifar10_quick_solver.prototxt
cifar10_quick_train_test.prototxt

首先修改cifar10_quick_train_test.prototxt的路径以及输出层数量（标注出黑体的部分）：

复制代码
name: "CIFAR10_quick"
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/my_simple_image/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/my_simple_image/ilsvrc12_train_lmdb"
    batch_size: 50    #一次训练的图片数量，一般指定50也够了
    backend: LMDB
  }
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/my_simple_image/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/my_simple_image/ilsvrc12_val_lmdb"
    batch_size: 50    #一次训练的图片数量
    backend: LMDB
  }
}

..........

layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  ..........
  inner_product_param {
    num_output: 3      #输出层数量，就是你要分类的个数
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
......
复制代码
 

cifar10_quick_solver.prototxt的修改根据自己的实际需要：

复制代码
net: "examples/my_simple_image/cifar/cifar10_quick_train_test.prototxt"   #网络文件路径
test_iter: 20        #测试执行的迭代次数
test_interval: 10    #迭代多少次进行测试
base_lr: 0.001       #迭代速率，这里我们改小了一个数量级，因为数据比较少
momentum: 0.9
weight_decay: 0.004
lr_policy: "fixed"   #采用固定学习速率的模式display: 1           #迭代几次就显示一下信息，这里我为了及时跟踪效果，改成1
max_iter: 4000       #最大迭代次数
snapshot: 1000       #迭代多少次生成一次快照
snapshot_prefix: "examples/my_simple_image/cifar/cifar10_quick"     #快照路径和前缀
solver_mode: CPU     #CPU或者GPU
复制代码
 

5、开始训练

运行下面的命令，开始训练（为了方便可以做成脚本）

./build/tools/caffe train --solver=examples/my_simple_image/cifar/cifar10_quick_solver.prototxt
 

6、小技巧

网络的配置和训练其实有一些小技巧。

- 训练过程中，正确率时高时低是很正常的现象，但是总体上是要下降的

- 观察loss值的趋势，如果迭代几次以后一直在增大，最后变成nan，那就是发散了，需要考虑减小训练速率，或者是调整其他参数

- 数据不能太少，如果太少的话很容易发散